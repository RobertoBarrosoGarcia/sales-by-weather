{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcd9e16",
   "metadata": {},
   "source": [
    "### Configuración de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8970cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manejo de dataset y cálculos numéricos\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"ml_amazon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e64e61",
   "metadata": {},
   "source": [
    "# Recopilación de datos\n",
    "A partir de este punto se reúnen todos los datos necesarios en caso de no tenerlos ya, para poder entrenar el modelo y realizar predicciones. Estos datos son los siguientes:\n",
    "\n",
    "+ Ordenes: Es el set de datos proporcionado por el cliente, con toda la información de las ventas realizadas. La información clave que vamos a extraer es:\n",
    "    - Fecha\n",
    "    - Ciudad\n",
    "    - Producto\n",
    "    - Cantidad vendida\n",
    "    - Precio de la unidad\n",
    "\n",
    "+ Clima: Nos da la información meteorológica de las ciudades más importantes donde vende el cliente:\n",
    "    - Fecha\n",
    "    - Ciudad\n",
    "    - Velocidad del viento\n",
    "    - Precipitaciones\n",
    "    - Nieve\n",
    "    - Profundidad de la nieve\n",
    "    - Temperatura media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92839ebb",
   "metadata": {},
   "source": [
    "## Lectura dataset de ordenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1aeb913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>B00B4S6SLW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>B00NM9HO3W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Slough</td>\n",
       "      <td>B07JP2ZRT9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>San Fernando</td>\n",
       "      <td>B07CMJ5186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>New Braunfels</td>\n",
       "      <td>B00PUI9WKG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE           CITY     PRODUCT  QUANTITY  PRICE\n",
       "0  2019-01-01     Cincinnati  B00B4S6SLW       1.0  99.00\n",
       "13 2019-01-01      Stuttgart  B00NM9HO3W       1.0  36.00\n",
       "12 2019-01-01         Slough  B07JP2ZRT9       1.0  69.99\n",
       "10 2019-01-01   San Fernando  B07CMJ5186       1.0  55.00\n",
       "9  2019-01-01  New Braunfels  B00PUI9WKG       1.0  30.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders = pd.read_excel('ordenes(01-01-2019_29_08_2021).xlsx', index_col=0)\n",
    "df_orders = df_orders.loc[:, ['purchase-date','ship-city','asin','quantity','item-price']]\n",
    "df_orders.dropna(inplace=True)\n",
    "new_date = []\n",
    "for date in df_orders['purchase-date']:\n",
    "    new_date.append(datetime.strptime(date, '%Y-%m-%dT%H:%M:%S+00:00').strftime('%Y-%m-%d'))\n",
    "df_orders['purchase-date'] = new_date\n",
    "cities = []\n",
    "for city in df_orders['ship-city']:\n",
    "    cities.append(city.title())\n",
    "df_orders['ship-city'] = cities\n",
    "df_orders = df_orders.groupby(['purchase-date','ship-city','asin']).sum().reset_index()\n",
    "df_orders.rename(columns={'purchase-date':'DATE','ship-city':'CITY','asin':'PRODUCT','quantity':'QUANTITY','item-price':'PRICE'},\n",
    "               inplace=True)\n",
    "df_orders['DATE'] = pd.to_datetime(df_orders.DATE)\n",
    "df_orders = df_orders.sort_values('DATE',ascending=True)\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8421a",
   "metadata": {},
   "source": [
    "Comprobamos cuantas ciudades hay, además de cuantas veces aparece cada una (cuanto más aparezcan más compras se realizan desde allí), esto lo guardamos en un excel, para tenerlo por si acaso fuera necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En all_cities tendremos todas las ciudades sin duplicados\n",
    "all_cities = df_orders['CITY'].drop_duplicates()\n",
    "\n",
    "#Guardamos en un excel cuantas veces se repite cada ciudad\n",
    "num_all_cities = all_cities.value_counts().to_frame()\n",
    "num_all_cities.to_excel('num_all_cities.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc8374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Número total de ciudades\n",
    "cities = list(set(all_cities))\n",
    "print(\"Tenemos un total de \" + str(len(cities)) + \" ciudades.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d64db1",
   "metadata": {},
   "source": [
    "### Mediante Geolocator obtenemos geolocalización de las ciudades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd4ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_locations = pd.DataFrame([], columns = ['CITY' , 'LATITUDE', 'LONGITUDE'])\n",
    "latitude = []\n",
    "longitude = []\n",
    "altitude = []\n",
    "i=0\n",
    "for city in all_cities:\n",
    "    location = geolocator.geocode(city)\n",
    "    if location is not None:\n",
    "        df_locations.loc[i]=[ city, round(location.latitude), round(location.longitude) ]\n",
    "        print(\"Ciudad: \" + city + \" i: \" + str(i))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un excel cada ciudad con sus coordenadas\n",
    "df_locations.to_excel('all_cities.xlsx', index=False)\n",
    "df_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf2d5d",
   "metadata": {},
   "source": [
    "### Leemos el dataset que contiene cada ciudad con sus coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = pd.read_excel('all_cities.xlsx')\n",
    "df_locations = df_locations[['CITY','LATITUDE','LONGITUDE']]\n",
    "df_locations['LATITUDE'] = df_locations['LATITUDE'].astype(float)\n",
    "df_locations['LONGITUDE'] = df_locations['LONGITUDE'].astype(float)\n",
    "df_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a914d",
   "metadata": {},
   "source": [
    "### df_stations: Lectura dataset con datos de las estaciones de clima disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcf5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stations = pd.read_fwf('stations_info_USA.txt')\n",
    "df_stations = df_stations.drop(['ELE__N','CODE','NUMBER'], 1)\n",
    "df_stations.dropna()\n",
    "df_stations.rename(columns={'STATIONS__N':'STATIONS',\n",
    "                            'LAT___N':'LATITUDE',\n",
    "                            'LONG___N':'LONGITUDE',\n",
    "                            'ST':'STATE',\n",
    "                            'NAME_________________________M':'NAME'},\n",
    "               inplace=True)\n",
    "df_stations['LATITUDE'] = round(df_stations['LATITUDE'])\n",
    "df_stations['LONGITUDE'] = round(df_stations['LONGITUDE'])\n",
    "df_stations.to_excel('stations_info_USA.xlsx', index=False)\n",
    "df_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb3a17",
   "metadata": {},
   "source": [
    "### df_stations_merged: Ciudad y estación con coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_merged = pd.merge(df_stations, df_locations, left_on=['LATITUDE','LONGITUDE'], right_on=['LATITUDE','LONGITUDE'], how='right')\n",
    "df_stations_merged = df_stations_merged[['STATIONS','LATITUDE','LONGITUDE','CITY','NAME']]\n",
    "df_stations_merged.drop_duplicates()\n",
    "df_stations_merged.dropna(inplace=True)\n",
    "df_stations_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ebc28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_list = df_stations_merged['STATIONS'].drop_duplicates()\n",
    "stations = list(set(df_stations_merged['STATIONS']))\n",
    "print(\"Tenemos un total de \" + str(len(stations)) + \" estaciones climáticas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0631225",
   "metadata": {},
   "source": [
    "### Mediante API obtenemos los datos climáticos de cada estación (10 horas de ejecución)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bebc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather_data = pd.DataFrame()\n",
    "i=0\n",
    "for station in station_list:\n",
    "    url = \"https://www.ncei.noaa.gov/access/services/data/v1?dataset=daily-summaries&dataTypes=NAME,AWND,PRCP,SNOW,SNWD,TAVG&stations=\"+station+\"&startDate=2019-01-01&endDate=2021-08-29&units=metric&includeStationLocation=1&format=json\"\n",
    "    ## try catch y pass para que pase\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = json.loads(response.content)\n",
    "        if data is not None:\n",
    "            df_data = pd.json_normalize(data)\n",
    "            df_data.dropna(inplace=True)\n",
    "            df_weather_data = pd.concat([df_weather_data, df_data])\n",
    "            df_weather_data.dropna(inplace=True)\n",
    "            i=i+1\n",
    "            print(\"Station: \" + station + \", i: \" + str(i))\n",
    "    except:\n",
    "        print(\"Something went wrong\")\n",
    "    finally:\n",
    "        df_weather_data.to_excel('weather_data_USA.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da6cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather_data['LATITUDE'] = round(df_weather_data['LATITUDE'])\n",
    "df_weather_data['LONGITUDE'] = round(df_weather_data['LONGITUDE'])\n",
    "df_weather_merged = pd.merge(df_weather_data, df_locations, left_on=['LATITUDE','LONGITUDE'], right_on=['LATITUDE','LONGITUDE'], how='right')\n",
    "df_weather_merged.dropna(inplace=True)\n",
    "df_weather_merged.rename(columns={'PRCP':'PRECIPITATION',\n",
    "                            'SNWD':'SNOW_DEPTH',\n",
    "                            'TAVG':'TEMPERATURE',\n",
    "                            'AWND':'SPEED_WIND'},\n",
    "               inplace=True)\n",
    "df_weather_merged = df_weather_merged[['CITY','DATE','SPEED_WIND','PRECIPITATION','SNOW','SNOW_DEPTH','TEMPERATURE']]\n",
    "df_weather_merged = df_weather_merged.groupby(['DATE','CITY']).mean().reset_index()\n",
    "cities = []\n",
    "for city in df_weather_merged['CITY']:\n",
    "    cities.append(city.title())\n",
    "df_weather_merged['CITY'] = cities\n",
    "df_weather_merged['DATE'] = pd.to_datetime(df_weather_merged.DATE)\n",
    "df_weather_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cd26c",
   "metadata": {},
   "source": [
    "# Unión de los datos con las ordenes y climas (Definitivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7529f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>CITY</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>TEMPERATURE</th>\n",
       "      <th>SPEED_WIND</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>B00B4S6SLW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>New Braunfels</td>\n",
       "      <td>B00PUI9WKG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>B07GMJB5ZZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>-18.900000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Denver</td>\n",
       "      <td>B07GMJB5ZZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>-15.500000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>B01L9SOIHM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>19.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>B06Y44DZC4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.99</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>Miami</td>\n",
       "      <td>B00B4S6SLW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.00</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>Larchmont</td>\n",
       "      <td>B07CMJ5186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.99</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>New York</td>\n",
       "      <td>B07CMJ5186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.99</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>Hartsdale</td>\n",
       "      <td>B08N6Z4B75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.99</td>\n",
       "      <td>21.766667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6134 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE           CITY     PRODUCT  QUANTITY  PRICE  TEMPERATURE  \\\n",
       "0    2019-01-01     Cincinnati  B00B4S6SLW       1.0  99.00     8.500000   \n",
       "1    2019-01-01  New Braunfels  B00PUI9WKG       1.0  30.00     6.850000   \n",
       "2    2019-01-01         Duluth  B07GMJB5ZZ       1.0  60.00   -18.900000   \n",
       "3    2019-01-01         Denver  B07GMJB5ZZ       1.0  60.00   -15.500000   \n",
       "13   2019-01-02         Dallas  B01L9SOIHM       1.0  45.00     1.500000   \n",
       "...         ...            ...         ...       ...    ...          ...   \n",
       "6132 2021-08-29        Chicago  B06Y44DZC4       1.0  39.99    27.500000   \n",
       "6127 2021-08-29          Miami  B00B4S6SLW       1.0  97.00    29.600000   \n",
       "6126 2021-08-29      Larchmont  B07CMJ5186       1.0  59.99    21.766667   \n",
       "6128 2021-08-29       New York  B07CMJ5186       1.0  59.99    21.766667   \n",
       "6133 2021-08-29      Hartsdale  B08N6Z4B75       1.0  59.99    21.766667   \n",
       "\n",
       "      SPEED_WIND  PRECIPITATION  SNOW  SNOW_DEPTH  \n",
       "0       3.600000           0.00   0.0         0.0  \n",
       "1       5.000000           0.00   0.0         0.0  \n",
       "2       3.100000           0.00   0.0       360.0  \n",
       "3       2.300000           0.00   0.0         0.0  \n",
       "13      4.400000          19.30   0.0         0.0  \n",
       "...          ...            ...   ...         ...  \n",
       "6132    4.700000           7.10   0.0         0.0  \n",
       "6127    4.050000           0.25   0.0         0.0  \n",
       "6126    2.666667           0.00   0.0         0.0  \n",
       "6128    2.666667           0.00   0.0         0.0  \n",
       "6133    2.666667           0.00   0.0         0.0  \n",
       "\n",
       "[6134 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(df_orders, df_weather_merged, left_on=['DATE','CITY'], right_on=['DATE','CITY'], how='inner').reset_index()\n",
    "df_merged = df_merged[['DATE','CITY','PRODUCT','QUANTITY','PRICE','TEMPERATURE','SPEED_WIND','PRECIPITATION','SNOW','SNOW_DEPTH']]\n",
    "df_merged = df_merged.sort_values('DATE',ascending=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847f4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_excel('weather_city_orders.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
